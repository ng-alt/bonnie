bonnie++ (1.00b) unstable; urgency=low

  * Added more warnings to the compile and removed assertions.  Made some
    trivial changes to the code (like changing variable names) to stop the
    warnings.

  * Fixed the memory management problem on bonnie++, these made it not work on
    IA64 (and stopped it working correctly on most platforms).  Thanks to
    Electric Fence by Bruce Perens for the discovery of this.
    The worst part of it was introduced in testing this version, so it only
    hit me and my alpha-testers.

  * Fixed zcav for large numbers of data points.

  * Made zcav multi-threaded to test multiple hard drives at once.  Changed the
    way it works totally.

  * Removed some dependencies on extensions to the C++ standard which are not
    supported in all compilers, also removed some trivial header file issues.
    These were found in testing on Tru64Unix.

  * Fixed a bug in bonnie++, it would go into an infinite loop when the file
    creation tests had a non-zero size.

  * Made bonnie++ work for block-reads that return partial blocks, now it will
    print an error and do another read for the rest.

  * Made Bonnie++ accept machine names up to 4095 bytes and not crash if the
    name is longer.  Previously the limit was 20 bytes and it crashed when you
    exceeded it.

  * This version is fairly experimental but I'm releasing it now because I need
    wider testing of the new features.

 -- Russell Coker <russell@coker.com.au>  Fri, 25 Aug 2000 12:15:06 +0200

bonnie++ (1.00a) unstable; urgency=low

  * Added a 30 second startup delay when run as root.  A user lost some data
    because of running it as root, if they had run it as a regular account
    they would be OK.  I don't want this to happen again.

  * Zcav now displays an error if it can't read a single block.

  * Added some basic autoconf support which I will use to increase portability
    in future versions.

  * Now provides zcav.

  * Should compile with all old versions of gcc.

  * Fixed a warning on Alpha.

 -- Russell Coker <russell@coker.com.au>  Mon, 24 Apr 2000 23:34:02 +0100

bonnie++ (1.00) unstable; urgency=low

  * Now include ZCAV in the same package.  ZCAV package should disappear.

  * License is now GPL.  Tim Bray agrees to the GPL for his parts, the license
    conflict was stopping me from putting ZCAV into the archive.

  * ZCAV reads through a hard drive sequentially and reports the IO speeds for
    different zones of the drive.

  * Fixed a few minor issues with the documentation, and put the test programs
    in /usr/sbin as they aren't generally run by regular users.  Also use man
    section 8.

 -- Russell Coker <russell@coker.com.au>  Sat, 01 Mar 2000 12:01:00 +0100

bonnie++ (0.99j) unstable; urgency=low

  * 0.99h core dumped when you didn't specify "-b" for file creation tests,
    fixed.

 -- Russell Coker <russell@coker.com.au>  Sun, 05 Mar 2000 11:16:42 +0100

bonnie++ (0.99h) unstable; urgency=low

  * Fixed a variety of bugs in the semaphore code which were introduced in
    0.99g.

  * Fixed formatting of output.

  * Added "-b" option to sync all writes.

  * Changed the semaphore code to make it more easily hackable for BSD users,
    it won't compile as-is on BSD at the moment...

 -- Russell Coker <russell@coker.com.au>  Sun, 05 Mar 2000 11:16:42 +0100

bonnie++ (0.99g) unstable; urgency=low

  * Now use getopt() for checking command-line options.

  * Added new versions of fork and semaphore code, initially developed for
    postal.

  * Fixed the message that's displayed when bad command-line parameters are
    entered.

  * Version 1.[0-8]0 will use fork().  Version 1.90 and above will use POSIX
    threads and include the concurrant bonnie++ functionality I've been
    promising for so long.

 -- Russell Coker <russell@coker.com.au>  Wed, 23 Feb 2000 22:16:23 +0100

bonnie++ (0.99f) unstable; urgency=low

  * Added "-f" parameter to skip per-char tests and semaphore code to
    synchronise multiple instances of Bonnie++.  Thanks to
    Christian Kagerhuber <c.kagerhuber@t-online.net> for the patch!

  * Added srand() after the fork so each child gets different random numbers.

 -- Russell Coker <russell@coker.com.au>  Wed, 12 Jan 2000 16:45:28 +1100

bonnie++ (0.99e) unstable; urgency=low

  * Fixed the operation of "-x" parameter (used to just cause crashes).
 
  * Made it cleanly exit under some error conditions where it used to crash.

  * Improved the bonnie++ man page.
 
  * Fixed some checking of command-line parameters.

  * Merged code from the OS/2 port, needs lots of testing...

 -- Russell Coker <russell@coker.com.au>  Wed, 12 Jan 2000 16:45:28 +1100

bonnie++ (0.99d) unstable; urgency=low

  * Added some more functionality. Tests hard and soft link creation.

  * Fixed CSV output of <100 seeks per second.

 -- Russell Coker <russell@coker.com.au>  Sun, 21 Nov 1999 22:37:42 +0200

bonnie++ (0.99c) unstable; urgency=low

  * Fix some bugs with big IO (fseek related) and include man pages.

  * Made it always print the CSV data.

 -- Russell Coker <russell@coker.com.au>  Sun, 21 Nov 1999 22:37:42 +0200

bonnie++ (0.99b) unstable; urgency=low

  * Initial Release as a Debian package.


0.99
Files are created mode 0600 not 0777.

Fixed some bugs in 0.98 where the results from several tests were totally
wrong.

Now the random file code will take less CPU time when there are extremely
large numbers of files.

Changed the format of all the output files slightly.  Notable change is that
the percentages of CPU time are now rounded off to the nearest percent.  This
is because it's not that accurate anyway (results that are provably more than
1% wrong are not uncommon), and because I needed the extra 1 character per
field.  Also now it handles CPU time >100% properly.  This is for SMP systems
where more than 1 CPU is being used.  Concurrant Bonnie++ will return many
results significantly greater than 100% on OSs that work well with SMP.

Added a csv2txt.pl program.  The main aim of this is to display data well
for 80 column braille displays for the blind.

Added "-q" option for quiet mode (less output).

Now the "-n" option works on a multiple of 1024.  So "-n 10" means create
10240 files.  This change is to allow the output to display in the same
format and save space in display (who would want to test as a lower resolution
than per 1024 files anyway).

The -n option is now of the form "num[:max[:min]]" where max is the maximum
size (default 0) and min is the minimum size (default 0).  To simulate Squid
use a max of 15000 and a min of 300.  To simulate INN use a maximum of 4096
and a minimum of 512.

1.0 will be out soon!

0.98
Fixed a bug where the data size couldn't be an exact multiple of the size of
each file (1 gig).  Fixed a number of other minor bugs related to that and
added more error checking as well.
Changed the code to support up to 1000 files for the IO test, if each is a
gig then you can test a tera-byte of data.  Changing the code to have more
than 1000 files wouldn't be that difficult to do.

Use the new C++ type conversions.

0.97
I have stopped using cout/cerr and never plan to use them again.  They caused
me significant pain when trying to get it going on an ancient SGI system.

Also changed the code structure a bit to make it cleaner.  One advantage of
this is that there is now a "-x" option to tell bonnie++ to run the same test
a number of times (it's interesting to see the variance in the results).

Now use fflush() after writing each set of results.  This means that killing
the program unexpectedly won't result in results being lost.  Also fixes a
strange bug related to printf() on Linux which I am still looking into.


 -- Russell Coker <russell@coker.com.au>  Wed, 13 Oct 1999 22:15:53 +0200

Local variables:
mode: debian-changelog
End:
